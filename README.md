# CHATBOT
AI Chatbot with Full-Stack Web InterfaceThis project is a sophisticated chatbot that combines a traditional machine learning model for intent recognition with a large language model (LLM) for general conversational responses. It features a full-stack web interface, with a Python backend powered by Flask and a modern front-end using HTML, CSS (Tailwind CSS), and JavaScript.FeaturesDual-Response System: The chatbot first attempts to classify a user's query using a pre-trained Support Vector Machine (SVM) model. For common phrases like greetings, this provides a quick, low-latency response. For all other queries, it seamlessly falls back to the Gemini API for more creative and detailed answers.Web Interface: A clean, responsive web interface allows users to interact with the chatbot in a modern chat environment.Persistent Chat History: All conversations are saved to a local history.txt file on the backend, ensuring a persistent record of your chats.Theming: The interface includes a dark/light mode switch for user preference.Simplified Backend: All backend logic is contained within a single app.py file, making the project easy to manage and deploy.PrerequisitesTo run this project, you will need:Python 3.xpip (Python package installer)Gemini API Key: A valid API key from Google's AI Studio.Installation and SetupFollow these steps to get the chatbot up and running on your local machine.1. Clone the RepositoryClone this project from the provided GitHub URL to your local machine.git clone [https://github.com/sushmithaHebbar/CHATBOT.git](https://github.com/sushmithaHebbar/CHATBOT.git)
cd CHATBOT
2. Set Up Your EnvironmentIt is highly recommended to use a virtual environment to manage dependencies.python -m venv venv
# On Windows
.\venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
3. Install DependenciesInstall all the required Python libraries using the requirements.txt file.pip install -r requirements.txt
4. Configure Your API KeyCreate a .env file in the root directory of the project and add your Google Gemini API key to it.API_KEY="YOUR_API_KEY_HERE"
5. Run the ServerYour app.py file contains both the model training and the Flask server. The first time you run it, it will train the model and save the necessary files (chatbot_model.pkl, words.pkl, classes.pkl).python app.py
You should see output indicating that the Flask server is running on http://127.0.0.1:5000.UsageOpen your web browser and navigate to http://127.0.0.1:5000.You will see the chatbot interface.Type your message into the input box and press Enter or click the send button.The chatbot will respond based on its intent-recognition model or by generating a response from the Gemini API. Your chat history will be stored locally and accessible through the sidebar.
